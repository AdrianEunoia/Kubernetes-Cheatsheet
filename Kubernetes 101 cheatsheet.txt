Sección Kubernetes 101

    Kubectl es la herramienta en linea de comandos para controlar los clusters de Kubernetes
    Su gramatica común es -> Kubectl comando recurso nombre argumentos
        Comando: verbo, como crear, borrar, editar...
        Recurso: es el tipo de objeto o recurso sobre el que queremos que se accione, pueden ser nodos, pods, servicios, deployments...
        Nombre: el nombre del recurso.
        Argumentos: pueden ser variados.
    
    Comandos básicos:
    Obtener la lista de nodos de nuestro cluster
        Kubectl get nodes (Opcional añadir nombre y obtener unicamente ese)
        Kubectl get nodes -o wide (Respuesta mas completa)
        Kubectl get nodes -o json (Respuesta mas completa en forma de JSON)

    Manifest
    ¿Qué es?
    Es un fichero en formato JSON o YAML que utilizamos para definir los objetos que creamos en nuestro cluster y trackear sus cambios, podemos almacenarlo como una version de fichero y así escalarlo (GIT), se puede trabajar sin estos ficheros pero es mas laborioso. Su estructura es:
        apiversion: para saber que version estamos atacando.
        kind: tipo de objeto que vamos a trabajar.
        metadatos: con claves y subclaves.
        spec: definimos el objeto, imagen, replica, etc... Varia dependiendo del objeto que saber.
    Para crear un objeto podemos hacerlo en una estructura como esta:
        apiVersion: apps/v1 
        kind: Deployment
        metadata:
        name: nginx-deployment
        spec:
        selector:
            matchLabels:
            app: nginx
        replicas: 1
        template:
            metadata:
            labels:
                app: nginx
            spec:
            containers:
            - name: nginx
                image: nginx:latest
                ports:
            - containerPort: 80
    Su comando equivalente sería
        kubectl run nginx --image=nginx:latest --port 80 --replicas=1
    Para borrar ambos sería, en primer y segundo caso:
        kubectl delete -f ejemplo.yaml
        kubectl delete deployment nginx

    Pods:
    ¿Qué es?
    Es el objeto minimo que se despliega en Kubernetes, no así el contenedor, el pod siempre incluye al menos un contenedor. Un pod se inicia y es un contenedor con un proceso corriendo en primer plano, por lo general el comando que especificamos en la imagen. Si el pod muere el scheduler manda levantar otro.
    Los eventos de un pod muestran lo que ha ocurrido durante su lanzamiento.
    Para levantar un pod desde un Manifest
        kubectl apply -f pod1.yaml  
    Para obtener la descripción de ese pod
        kubectl describe pod nginx
    Para borrar ambos sería, en primer y segundo caso:
        kubectl delete pod nginx
        kubectl delete -f pod1.yaml

    Metadatos, labels y selectors (De pods)
    Tipos de metadatos:
        Hay nombre, etiquetas (labels), se describen como cualquier otra caracteristica del .yaml
        Selectors: permiten obtener info o referirnos a un objeto a traves de sus etiquetas para poder filtrar.
        Por ejemplo al desplegar un balanceador de carga, le indicamos a que pods tiene que hacer referencia según una serie de selectores.
        Para obtener un pod con una etiqueta concreta
            kubectl get pods --selector project=nginx
        Para obtener los pods que contengan esa etiqueta
            kubectl get pods -l nginx
        
    Replicas o pods gestionados
    ¿Qué es un replication controller?
    Es un recurso que nos permite lanzar pods de manera organizada, copias, para por ejemplo si hay alguna copia ocupada, se encarga otra
    Replication controller está obsoleto, ahora se trabaja con Replica sets
    El ejemplo de un replication controller es:
        apiVersion: v1
        kind: ReplicationController
        metadata:
        name: nginx-testing
        spec:
        replicas: 3
        selector:
            project: nginx
            environment: testing
        template:
            metadata:
            name: nginx
            labels:
                project: nginx
                environment: testing
            spec:
            containers:
            - name: nginx
                image: nginx
                ports:
                - containerPort: 80
    Para ver todas las replicas y el padre 
        kubectl get all // kubectl get replicationcontroller
    Para subir el numero de replicas
        Editas el fichero y lo escalas
        kubectl scale replicationcontroller nginx-testing --replicas=3
    Para describirlo y ver sus eventos, esto es interesante ves su tracking
        kubectl describe rc nginx
    Para eliminarlos a todos
        kubectl delete -f pod-replicationcontroller.yaml 
    Para eliminar el replicationcontroller pero no sus pods creados
        kubectl delete rc nginx-testing --cascade=false
        
    Replicas con ReplicaSets
    Es la forma mas actual de gestionar las replicas
    La estructura de un ReplicaSet es:
        apiVersion: apps/v1
        kind: ReplicaSet
        metadata:
        name: nginx-testing
        spec:
        replicas: 5
        selector:
            matchLabels:
            app: nginx
            environment: testing
        template:
            metadata:
            labels:
                app: nginx
                environment: testing
            spec:
            containers:
            - name: nginx
                image: nginx
                ports:
            - containerPort: 80
    Introduce una nueva forma de trabajar con selectores, mas avanzada que con replicationcontroller.
    Además en el selector podemos añadir esta serie de caracteristicas:
        matchExpressions:
        - {key: environment, operator: In, values: [testing]}
        No lo hemos utilizado pero lo debemos tener en cuenta

    Servicios
    ¿Qué es?
    Cada pod obtiene su IP diferente, los pods pueden escalar, y vamos a necesitar que se haga un balanceo de carga que vaya enviando a los pods el tráfico. Para esto necesitamos que algun elemento de red se ponga entre el servicio final y el pod, para esto se usan los SERVICIOS, una abstraccion que define un conjunto de pods y su politica.
    El servicio consta de un DNS y una IP, los servicios son encontrables dentro del cluster sin saber su IP.
    Los principio o caracteristicas de los servicios se definen de esta manera:
        apiVersion: v1
        kind: Service
        metadata:
            name: servicio1
        spec:
        selector:
            app: nginx
            environment: testing
        ports:
            - protocol: TCP
            port: 80
    Existen diferentes tipos de servicio pueden ser ClusterIP, NodePort, LoadBalancer o ExternalName
    - ClusterIP: lo usamos para exponer un servicio en una IP interna de nuestro cluster, ese servicio es accesible solo dentro del cluster, es util para cuando tenemos muchos microservicios.
    - NodePort: lo usamos cuando exponemos un servicio en la IP principal en los nodos del cluster, desde cualquier nodo podemos llegar al servicio, facilita el balance de trafico desde fuera.
    - LoadBalancer: exponemos un servicio externamente usando un balanceador de carga de un proveedor de cloud, de esta forma tenemos un acceso interno, externo y a un nodo.
    - ExternalName: cuando recibe una petición devuelve el valor de un DNS tipo CNAME, se usa para cambiar a donde apunta un recurso sin necesidad de cambiar el DNS.

    Servicios: ClusterIP
    Lo usamos para exponer un conjunto de pods para que se pueda llegar a ellos en conjunto desde dentro del cluster. Por ejemplo, tenemos 5 pods replicados, y queremos que un servicio balancee las peticiones, lo que diferencia al ClusterIP del resto de servicios es que solo accesible desde dentro.
    El selector del servicio busca las etiquetas de los pods para saber dónde enviar el tráfico. Podemos añadir etiquetas a nuestro servicio.
    Desde dentro un nodo o un pod si que podemos acceder, hacer un curl, pero desde fuera no, hacemos un exec -it bash o un minikube ssh y consultamos.
    Para describir un servicio 
        kubectl describe service servicio-clusterip
    Para borrar un servicio
        kubectl delete service -f servicio-clusterip
    Para borrar todos los recursos del sitio en el que estoy
        kubectl delete -f .

    Servicios: NodePort
    Es la misma estructura vista anteriormente, tiene un puerto externo, quiere decir que se crea un puerto efimero o de cliente, se puede acceder como el anterior, con minikube ssh.
    Tenemos que acceder al nodo para consultar, es decir, ahora que estamos en local con un solo nodo, montado con minikube, ejecutaremos el comando minkube IP y lo tendremos. Consultado a la IP del nodo con el puerto que ha definido el servicio el trafico ya se redirige, sin entrar al pod directamente.
    minikube ip -> curl 192.168.99.104:32230
    Este puerto es extraño, así que con un proxy externo todo el trafico podrá ser redirigido del domnio al puerto especifico. Si lo borramos y levantamos la IP cambia así quie tenemos que definir un puerto fijo de esta forma:
        apiVersion: v1
        kind: Service
        metadata:
        name: servicio-nodeport
        spec:
        type: NodePort
        selector:
            app: nginx
            environment: testing-nodeport
        ports:
            - protocol: TCP
            port: 80
            nodePort: 32000
    Esto nos sirve para por ejemplo desde el balanceador de carga del cloud apunta a los nodos de nuestro cluster que envia el trafico al puerto especifico. El LoadBalancer facilita todo esto.

    Servicios: LoadBalancer
    No se pueden probar usando minikube porque necesitamos mas de un cluster, se verá en la seccion de 102.

    Servicios: ExternalName
    Nos permiten crear un alias DNS que se aplica dentro del cluster, se usa mucho para migraciones.

    Volumenes:
    Cómo sabemos el almacenamiento en los contenedores es efimero, por lo que docker implementa un sistema de persistencia a partir de volumenes. Esto tambien nos permite compartir contenido entre diferentes pods, donde habrán ficheros comunes. Existen diferentes tipos de volumenes, directorio en nodos, en cloud (EBS) o cluster EFS.
    - Volumenes asociados a un contenedor: al levantar un contenedor se crea un volumen, que guarda la diferencia entre la imagen real y las modificaciones que se hagan, al morir el contenedor se pierde el volumen, por lo tanto los datos.
    - Persistent volumes.

    Volumenes: Persistent volume:
    Si hay varios clusters, la ubicacion de montage debe estar compartida.
    Para obtener los Persistent volumes activos y sus claims
        kubectl get persistentvolumes
        kubectl get pvc
    Creamos un volumen 
        kubectl apply -f pv-volume-001.yaml 
    ¿Cómo le indicamos al volumen que va a ser de alguien? -> Con el fichero claim.yaml. Es importante que se defina bien el volumen e igual el claim
        kubectl apply -f claim.yaml
    El estado del PV cambiará de pending a bound, porque ya está siendo ligado
    Describimos el claim para ver sus detalles
        kubectl describe pvc pv-volume-claim-1
    Un ejemplo de pod en el que se relaciona el volumen, su claim y montage es:
        kind: Pod
        apiVersion: v1
        metadata:
        name: pv-pod
        spec:
        volumes:
            - name: pv-storage
            persistentVolumeClaim:
            claimName: pv-volume-claim-1
        containers:
            - name: pv-container
            image: nginx:1.7.9
            ports:
                - containerPort: 80
            volumeMounts:
                - mountPath: "/usr/share/nginx/html"
                name: pv-storage
    Para un sistema basado en replicas es exactamente igual, y los pods accederan a ese directorio, y será compartido.
    IMPORTANTE!
    El punto de montage de los Persistent Volumes está en minikube, es decir, la ruta /mnt/data/pv-loquesea será accesible desde minikube, desde cada cluster si fueran más, en nuestro caso volvemos a entrar con minikube ssh.
    Un volumen no se puede borrar si está siendo claimeado

    ConfigMaps:
    Son elementos que nos permiten desacoplar configuración de nuestros contenedores con algo dentro que sirven para un fin. Son valores de configuración que pasamos a los contenedores en el momento de su creacion, pueden ser variables, directorios o ficheros.
    No son recomendables para insertar codigo, están mas pensado para configuraciones simples del sistema.
    Para obtener los ConfigMaps de nuestro sistema
        kubectl get cm
    (1) Para crear un ConfigMaps desde la linea de comando que contenga una variable
        kubectl create configmap test-cm --from-literal variable1=valor1
    Para obtenerlos y su descripcion
        kubectl get cm -o yaml
    Para describirlos
        kubectl describe cm test-cm
    Para simular un manifest (yaml)
        kubectl create configmap test-cm --from-literal variable1=valor1 --from-literal varible2=valor2 --dry-run -o yaml
    Para crear un pod e insertarle ConfigMaps mediante ficheros
        Primero creamos los configmaps, ejemplo:
        server {
            listen       80;
            server_name  videocursoscloud.com;

            location / {
                root   /usr/share/nginx/html;
                index  index.html index.htm;
            }
        }
        Despues se lo pasamos en el manifest del pod, ejemplo
        apiVersion: v1 
        kind: Pod 
        metadata:
        name: nginx-cm-file 
        spec:
        containers:
            - name: nginx
            image: nginx
            volumeMounts:
            - name: config-volume
                mountPath: /etc/nginx/conf.d/
        volumes:
            - name: config-volume
            configMap:
                name: nginx-config-dir (Directorio con los ficheros de configuración)
    
    Secrets:
    ¿Qué es?
    Son similares a los configmaps a diferencia de ellos que van cifrados en el servidor, los usamos preferentemente para almacenar usuarios, claves, SSH, para que posteriormente los usuarios puedan acceder a ellos.
    Hay difentes tipos de Secrets:
    Para crear un secret y guardarlo a partir de un fichero:
        kubectl create secret generic credenciales --from-file=./username --from-file=./password
    Para obtener todos los secrets almacenados:
        kubectl get secrets
    Para obtener la definición en forma de YAML: (El yaml muestra los credenciales no cifrados pero en B64)
        kubectl create secret generic credenciales --from-file=./username --from-file=./password --dry-run -o yaml
    Para aplicarlo, una vez ya está creado
        kubectl apply -f credenciales.yaml
    Para ver su contenido
        kubectl get secret credenciales-manifest -o yaml
    La forma de operar con los secrets es igual que con los ConfigMaps, es decir, montamos en el contenedor (volumen) del pod el secret, la manera de indicarselo es la que se muestra a continuación, podemos hacer la prueba entrando al pod corriendo y comprobar las credenciales:
        apiVersion: v1
        kind: Pod
        metadata:
        name: nginx-secrets-mount
        spec:
        containers:
        - name: nginx
            image: nginx:1.7.9
            volumeMounts:
            - name: secrets
            mountPath: "/etc/secrets"
            readOnly: true
        volumes:
        - name: secrets
            secret:
            secretName: credenciales-manifest